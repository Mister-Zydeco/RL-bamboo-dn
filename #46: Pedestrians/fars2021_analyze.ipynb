{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "ANALYSIS NOTEBOOK:  To run this notebook, you should have first run the fars2021_getzips and the fars2021_makedfs notebooks. These notebooks downloads the NHTSA accident data for 2010-2021, aggregate the accident and person data from those years into an accident and a person dataframe, and pickle the two dataframes. With this approach, all we have to do to get the data in an easy-to-analyze form is to unpickle two files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATADIR = './data'\n",
    "person_fields = ['YEAR', 'STATE', 'ST_CASE', 'PER_TYP', 'INJ_SEV']\n",
    "accident_fields = ['YEAR', 'STATE', 'ST_CASE', 'LGT_COND']\n",
    "with open(f'{DATADIR}/person.pickle', 'rb') as person_fh:\n",
    "    all_person_cases = pickle.load(person_fh)\n",
    "with open(f'{DATADIR}/accident.pickle', 'rb') as accident_fh:\n",
    "    all_accident_cases = pickle.load(accident_fh)\n",
    "    \n",
    "print(all_accident_cases.shape)\n",
    "print(all_person_cases.shape)\n",
    "print(all_person_cases.query('PER_TYP == 5 & ((INJ_SEV == 3) | (INJ_SEV == 4))').shape)\n",
    "all_person_cases['PER_TYP'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_fields = ['STATE', 'ST_CASE', 'YEAR']\n",
    "\n",
    "all_pedestrian_cases = all_person_cases.query('PER_TYP == 5')\n",
    "\n",
    "\n",
    "all_ped_accident_cases = pd.merge(all_pedestrian_cases, all_accident_cases,\n",
    "                                 on=case_id_fields)\n",
    "years = list(range(2012, 2022))\n",
    "\n",
    "def count_unique(df, fields):\n",
    "    return df.drop_duplicates(fields).shape[0]\n",
    "\n",
    "total_ped_accidents = count_unique(all_pedestrian_cases, case_id_fields)\n",
    "all_sid_ped_cases = all_pedestrian_cases.query(\n",
    "    '(INJ_SEV == 3) | (INJ_SEV == 4)'\n",
    ")\n",
    "total_sid_ped_accidents = count_unique(all_sid_ped_cases, case_id_fields)\n",
    "\n",
    "pct_sid_ped_accidents = pd.DataFrame({\n",
    "    'PED_ACCIDENTS': [total_ped_accidents],\n",
    "    'SID_PED_ACCIDENTS': [total_sid_ped_accidents],\n",
    "    'PERCENT_SID': [100 * total_sid_ped_accidents / total_ped_accidents]\n",
    "})\n",
    "print(pct_sid_ped_accidents.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accident_counts_by_year = [\n",
    "    count_unique(all_person_cases.query('YEAR == @yr'), case_id_fields)\n",
    "    for yr in years\n",
    "                \n",
    "]\n",
    "pedestrian_accident_counts_by_year = [\n",
    "    count_unique(all_pedestrian_cases.query('YEAR == @yr'), case_id_fields)\n",
    "    for yr in years\n",
    "]\n",
    "ped_freq_df = pd.DataFrame({\n",
    "    'YEAR': years,\n",
    "    'TOTAL_ACCIDENTS': total_accident_counts_by_year,\n",
    "    'PED_ACCIDENTS': pedestrian_accident_counts_by_year,\n",
    "})\n",
    "ped_freq_df['PCT_PED_ACCIDENTS'] = (\n",
    "    100.0 * ped_freq_df['PED_ACCIDENTS'] / ped_freq_df['TOTAL_ACCIDENTS']\n",
    ")\n",
    "\n",
    "print(ped_freq_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_st = [str(yr) for yr in range(2012, 2022)]\n",
    "plt.figure(1)\n",
    "plt.title((\n",
    "    'Precentage pedestrian involvement\\n'\n",
    "    'in accidents by year')\n",
    ")\n",
    "plt.plot(years_st, ped_freq_df['PCT_PED_ACCIDENTS'].to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_counts = {\n",
    "    'Accidents with pedestrians': ped_freq_df['PED_ACCIDENTS'].to_numpy(),\n",
    "    'All accidents': ped_freq_df['TOTAL_ACCIDENTS'].to_numpy()\n",
    "}\n",
    "width, bottom = 0.3, np.zeros(10)\n",
    "\n",
    "plt.figure(2)\n",
    "for acc_type, acc_count in accident_counts.items():\n",
    "    p = plt.bar(years_st, acc_count, label=acc_type, bottom=bottom)\n",
    "    bottom += acc_count\n",
    "\n",
    "plt.title('Pedestrian-involved accidents 2012-2021')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lighting_codes = pd.DataFrame({\n",
    "    'LGT_COND': list(range(1,10)),\n",
    "    'LGT_COND_DESC': [\n",
    "        'Daylight', 'Dark -- Not Lighted', 'Dark -- Lighted',\n",
    "        'Dawn', 'Dusk', 'Dark -- Unknown Lighting', 'Other',\n",
    "        'Not Reported', 'Reported as Unknown'\n",
    "    ]\n",
    "})\n",
    "\n",
    "\n",
    "lighting_conditions = all_ped_accident_cases['LGT_COND'].value_counts()\n",
    "lighting_conditions = lighting_conditions.rename_axis('LGT_COND')\n",
    "lighting_conditions = lighting_conditions.reset_index(name='COUNT')\n",
    "lighting_conditions = pd.merge(lighting_conditions, lighting_codes,\n",
    "                               on='LGT_COND')\n",
    "print(lighting_conditions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.rcParams['figure.figsize'] = 11, 5\n",
    "pie = plt.pie(\n",
    "    lighting_conditions['COUNT'].to_numpy(),\n",
    "    autopct=lambda v: f'{v:.1f}%' if v > 15 else None\n",
    ")\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title(\n",
    "    ('Breakdown of lighting conditions\\n'\n",
    "    'pedestrian-involved accidents 2010-2021'),\n",
    "    loc='left'\n",
    ")\n",
    "\n",
    "\n",
    "n_lighting_conditions = lighting_conditions['COUNT'].sum()\n",
    "\n",
    "def one_place_if_lt_15pct(v):\n",
    "    x = 100.0 * v/n_lighting_conditions\n",
    "    return f' ({x:.1f}%)' if x <= 15.0 else ''\n",
    "\n",
    "lighting_conditions_aug = (\n",
    "    lighting_conditions['LGT_COND_DESC'] +\n",
    "    lighting_conditions['COUNT'].apply(one_place_if_lt_15pct)\n",
    ")\n",
    "plt.legend(pie[0], lighting_conditions_aug.to_numpy(),\n",
    "           loc='center left', bbox_to_anchor=(0.0,0.5),\n",
    "           bbox_transform=plt.gcf().transFigure)\n",
    "\n",
    "\n",
    "#plt.subplots_adjust(left=0.08, right=0.92, top=0.92, bottom=0.3,\n",
    "                   # wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
